{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09af0786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb234de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola, estoy funcionando correctamente. ¿En qué puedo ayudarte hoy?\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0)\n",
    "\n",
    "response = llm.invoke(\"Hola, ¿cómo estás?\")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "693639c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hola, estoy funcionando correctamente, gracias por preguntar. ¿En qué puedo ayudarte hoy?\n"
     ]
    }
   ],
   "source": [
    "gpt3_llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0)\n",
    "response = gpt3_llm.invoke(\"Hola como estas?\")\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5118dbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Tu nombre es Oskar. ¿De dónde eres, Oskar?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "msg_1 = SystemMessage(content=\"You are a helpful assistant that talks in spanish\")\n",
    "msg_2 = HumanMessage(content=\"Me llamo Oskar\")\n",
    "msg_3 = AIMessage(content=\"Hola Oskar, como estas?\")\n",
    "msg_4 = HumanMessage(content=\"Como me llamo?\")\n",
    "history = [msg_1, msg_2, msg_3, msg_4]\n",
    "response = gpt3_llm.invoke(history)\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65da3474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq es una empresa de tecnología de procesamiento de lenguaje de programación (TLP) que se especializa en la creación de hardware y software para acelerar el procesamiento de inteligencia artificial (IA) y aprendizaje automático (MA). Su tecnología se centra en la creación de procesadores de propósito especializados (ASIC) que están diseñados específicamente para ejecutar operaciones de IA y MA de manera eficiente.\n",
      "\n",
      "Groq ha desarrollado una plataforma de procesamiento de IA llamada \"Groq Chip\" que se utiliza para acelerar el procesamiento de modelos de IA y MA. Esta plataforma se basa en un procesador de propósito especializado que está diseñado para ejecutar operaciones de IA y MA de manera eficiente.\n",
      "\n",
      "En cuanto a los modelos de IA que soporta actualmente, Groq ha anunciado que su plataforma puede ejecutar una variedad de modelos de IA y MA, incluyendo:\n",
      "\n",
      "1. **Transformers**: Groq ha anunciado que su plataforma puede ejecutar modelos de Transformers, que son una clase de modelos de IA que se utilizan para tareas de procesamiento de lenguaje natural como la traducción automática y la generación de texto.\n",
      "2. **ResNets**: Groq también ha anunciado que su plataforma puede ejecutar modelos de ResNets, que son una clase de modelos de IA que se utilizan para tareas de procesamiento de imágenes como la detección de objetos y la clasificación de imágenes.\n",
      "3. **BERT**: Groq ha anunciado que su plataforma puede ejecutar modelos de BERT, que es un modelo de IA que se utiliza para tareas de procesamiento de lenguaje natural como la clasificación de texto y la generación de texto.\n",
      "4. **T5**: Groq también ha anunciado que su plataforma puede ejecutar modelos de T5, que es un modelo de IA que se utiliza para tareas de procesamiento de lenguaje natural como la traducción automática y la generación de texto.\n",
      "\n",
      "Es importante destacar que la lista de modelos de IA que soporta Groq puede variar con el tiempo, y la empresa puede agregar soporte para nuevos modelos en el futuro.\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "claude_llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0)\n",
    "response = claude_llm.invoke(\"¿Qué es Groq y qué modelos soporta actualmente?\")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83b7979a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Hola! Groq es una empresa estadounidense que se especializa en la creación de hardware y software para la aceleración de modelos de inteligencia artificial (IA) y aprendizaje automático (MA). Su tecnología se enfoca en la optimización de la eficiencia energética y la velocidad de procesamiento para aplicaciones de IA.\n",
      "\n",
      "Groq utiliza una arquitectura llamada \"Tensor Processing Unit\" (TPU) para acelerar la ejecución de modelos de IA. Esta arquitectura se diseñó específicamente para procesar operaciones matriciales, que son fundamentales en la mayoría de los algoritmos de IA.\n",
      "\n",
      "En cuanto a los modelos de IA que utiliza Groq, no tengo información actualizada sobre los modelos específicos que están utilizando en la actualidad. Sin embargo, puedo decirte que Groq se enfoca en la creación de hardware y software para la aceleración de modelos de IA de última generación, como:\n",
      "\n",
      "* Modelos de lenguaje natural (NLP)\n",
      "* Modelos de visión por computadora (CV)\n",
      "* Modelos de procesamiento de señales (SP)\n",
      "* Modelos de recomendación\n",
      "\n",
      "Groq también ha colaborado con varias empresas líderes en la industria de la IA, como Google, para desarrollar tecnologías de aceleración de IA.\n",
      "\n",
      "Es importante destacar que la información sobre los modelos de IA utilizados por Groq puede cambiar con el tiempo, y no tengo acceso a información en tiempo real. Si necesitas información más actualizada, te recomiendo visitar el sitio web de Groq o buscar fuentes de noticias y artículos especializados en la industria de la IA.\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0)\n",
    "\n",
    "response = llm.invoke(\"Hola, ¿puedes explicarme qué es Groq y qué modelos usa actualmente?\")\n",
    "\n",
    "print(response.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-agent (3.11.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
